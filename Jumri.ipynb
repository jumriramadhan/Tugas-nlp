{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1E-mhTz_wUYJ4vAImQ6NMw_NwdV9uoIbp",
      "authorship_tag": "ABX9TyOj5rk+RQvqCMuGfSIBZJ+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumriramadhan/Tugas-nlp/blob/main/Jumri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E73PoNLMHq1n",
        "outputId": "6b43cf01-faf7-49aa-85ba-dd65b341ae63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai==1.0.61 in /usr/local/lib/python3.11/dist-packages (1.0.61)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (1.4.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (1.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (4.13.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (3.10.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (2.10.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (2.0.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (7.352.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (2.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61) (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.61) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->fastai==1.0.61) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->fastai==1.0.61) (2.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai==1.0.61) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai==1.0.61) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.61) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.61) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.61) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.61) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->fastai==1.0.61) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->fastai==1.0.61) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install fastai==1.0.61"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/course-nlp-master/')\n",
        "from seq2seq import *"
      ],
      "metadata": {
        "id": "CFA0K8uOQKc2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "# Ganti dengan path folder tujuan Anda\n",
        "target_path = Path(\"/content/drive/MyDrive/course-nlp-master/giga-fren\")\n",
        "target_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. Simpan file dummy data_save.pkl\n",
        "dummy_data = {\"info\": \"Dummy data for testing only\"}\n",
        "with open(target_path / \"data_save.pkl\", \"wb\") as f:\n",
        "    pickle.dump(dummy_data, f)\n",
        "\n",
        "# 2. Simpan embedding dummy fr_emb.pth dan en_emb.pth\n",
        "# Ukuran kecil supaya ringan\n",
        "fr_emb = torch.randn((10, 8))\n",
        "en_emb = torch.randn((10, 8))\n",
        "torch.save(fr_emb, target_path / \"fr_emb.pth\")\n",
        "torch.save(en_emb, target_path / \"en_emb.pth\")\n",
        "\n",
        "print(\"✅ Dummy files berhasil dibuat di:\", target_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meF-xeHbUnP6",
        "outputId": "77c443a2-800f-4622-f1cc-d160af8f0898"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dummy files berhasil dibuat di: /content/drive/MyDrive/course-nlp-master/giga-fren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "model_path = Path('/content/drive/MyDrive/course-nlp-master/giga-fren')\n",
        "emb_enc = torch.load(model_path / 'fr_emb.pth')\n",
        "emb_dec = torch.load(model_path / 'en_emb.pth')\n",
        "\n",
        "print(\"✅ Loaded dummy embeddings successfully!\")\n",
        "print(\"Encoder shape:\", emb_enc.shape)\n",
        "print(\"Decoder shape:\", emb_dec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXToMIq3QPEN",
        "outputId": "ac95476c-c9fe-44a6-e493-543ee1bba9b6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded dummy embeddings successfully!\n",
            "Encoder shape: torch.Size([10, 8])\n",
            "Decoder shape: torch.Size([10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqRNN_attn(nn.Module):\n",
        "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
        "        super().__init__()\n",
        "        self.nl,self.nh,self.out_sl,self.pr_force = nl,nh,out_sl,1\n",
        "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
        "        self.emb_enc,self.emb_dec = emb_enc,emb_dec\n",
        "        self.emb_sz_enc,self.emb_sz_dec = emb_enc.embedding_dim,emb_dec.embedding_dim\n",
        "        self.voc_sz_dec = emb_dec.num_embeddings\n",
        "\n",
        "        self.emb_enc_drop = nn.Dropout(0.15)\n",
        "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25,\n",
        "                              batch_first=True, bidirectional=True)\n",
        "        self.out_enc = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
        "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2*nh, self.emb_sz_dec, num_layers=nl,\n",
        "                              dropout=0.1, batch_first=True)\n",
        "        self.out_drop = nn.Dropout(0.35)\n",
        "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
        "        self.out.weight.data = self.emb_dec.weight.data\n",
        "\n",
        "        self.enc_att = nn.Linear(2*nh, self.emb_sz_dec, bias=False)\n",
        "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
        "        self.V =  self.init_param(self.emb_sz_dec)\n",
        "\n",
        "    def encoder(self, bs, inp):\n",
        "        h = self.initHidden(bs)\n",
        "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
        "        enc_out, hid = self.gru_enc(emb, 2*h)\n",
        "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1,2,0,3).contiguous()\n",
        "        pre_hid = pre_hid.view(self.nl, bs, 2*self.nh)\n",
        "        hid = self.out_enc(pre_hid)\n",
        "        return hid,enc_out\n",
        "\n",
        "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
        "        hid_att = self.hid_att(hid[-1])\n",
        "        u = torch.tanh(enc_att + hid_att[:,None])\n",
        "        attn_wgts = F.softmax(u @ self.V, 1)\n",
        "        ctx = (attn_wgts[...,None] * enc_out).sum(1)\n",
        "        emb = self.emb_dec(dec_inp)\n",
        "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:,None], hid)\n",
        "        outp = self.out(self.out_drop(outp[:,0]))\n",
        "        return hid, outp\n",
        "\n",
        "    def forward(self, inp, targ=None):\n",
        "        bs, sl = inp.size()\n",
        "        hid,enc_out = self.encoder(bs, inp)\n",
        "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "        enc_att = self.enc_att(enc_out)\n",
        "\n",
        "        res = []\n",
        "        for i in range(self.out_sl):\n",
        "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
        "            res.append(outp)\n",
        "            dec_inp = outp.max(1)[1]\n",
        "            if (dec_inp==self.pad_idx).all(): break\n",
        "            if (targ is not None) and (random.random()<self.pr_force):\n",
        "                if i>=targ.shape[1]: continue\n",
        "                dec_inp = targ[:,i]\n",
        "        return torch.stack(res, dim=1)\n",
        "\n",
        "    def initHidden(self, bs): return one_param(self).new_zeros(2*self.nl, bs, self.nh)\n",
        "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
      ],
      "metadata": {
        "id": "Sy7GB6CeYTV0"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# fr_emb dan en_emb adalah tensor\n",
        "# Konversi ke nn.Embedding\n",
        "emb_enc = nn.Embedding.from_pretrained(fr_emb)\n",
        "emb_dec = nn.Embedding.from_pretrained(en_emb)"
      ],
      "metadata": {
        "id": "6GagCuDvYUnN"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30)"
      ],
      "metadata": {
        "id": "hFMtdhIqYq8U"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text import TextDataBunch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from fastai.basic_data import DataBunch\n",
        "\n",
        "# Dummy input & target tensors\n",
        "x_dummy = torch.randint(0, 10, (8, 5))  # 8 samples, 5 tokens each\n",
        "y_dummy = torch.randint(0, 10, (8, 5))\n",
        "\n",
        "# Buat dataset dan DataLoader\n",
        "train_ds = TensorDataset(x_dummy, y_dummy)\n",
        "valid_ds = TensorDataset(x_dummy, y_dummy)\n",
        "train_dl = DataLoader(train_ds, batch_size=4)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=4)\n",
        "\n",
        "# Buat DataBunch\n",
        "data = DataBunch(train_dl, valid_dl)\n"
      ],
      "metadata": {
        "id": "GqsOjvmxYuTT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(data, model, loss_func=seq2seq_loss, metrics=seq2seq_acc)\n",
        "learn.fit_one_cycle(5, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hu_A-7WCZCvb",
        "outputId": "3a8705de-17a2-49ef-c1c5-0e604dd0092c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.931677</td>\n",
              "      <td>2.346272</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.186545</td>\n",
              "      <td>2.278042</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.987160</td>\n",
              "      <td>2.246424</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.944333</td>\n",
              "      <td>2.194860</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.931290</td>\n",
              "      <td>2.205694</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.save('5')"
      ],
      "metadata": {
        "id": "igefi-EOZeLw"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(data, model, loss_func=seq2seq_loss, metrics=seq2seq_acc)\n",
        "learn.fit_one_cycle(5, 3e-3)\n",
        "learn.save('5')"
      ],
      "metadata": {
        "id": "jnFvF9zlZigY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a86ae0a6-eb96-4f4a-b828-5a87d74a82da"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>seq2seq_acc</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.938486</td>\n",
              "      <td>2.121135</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.960178</td>\n",
              "      <td>2.054171</td>\n",
              "      <td>0.329167</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.865897</td>\n",
              "      <td>2.228474</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.860582</td>\n",
              "      <td>2.186399</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.839330</td>\n",
              "      <td>2.157602</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preds_acts(learn, ds_type=DatasetType.Train):\n",
        "    learn.model.eval()\n",
        "    rxs, rys, rzs, xs, ys, zs = [], [], [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in progress_bar(learn.dl(ds_type)):\n",
        "            out = learn.model(xb)\n",
        "            for x, y, z in zip(xb, yb, out):\n",
        "                rxs.append(x)\n",
        "                rys.append(y)\n",
        "                preds = z.argmax(1)\n",
        "                rzs.append(preds)\n",
        "                xs.append(x.tolist())\n",
        "                ys.append(y.tolist())\n",
        "                zs.append(preds.tolist())\n",
        "    return rxs, rys, rzs, xs, ys, zs"
      ],
      "metadata": {
        "id": "jlJJ8rUaZ094"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rxs,rys,rzs,xs,ys,zs = preds_acts(learn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "detyy4R6a3Hx",
        "outputId": "5eb7c102-9714-4f96-cd6b-ee6d2990252a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(rxs), len(rys), len(rzs), len(xs), len(ys), len(zs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG4IJiNha5s_",
        "outputId": "38915c3e-fbf7-419a-c3cf-3648f7a2e420"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 8 8 8 8 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 3  # atau angka < panjang minimum dari list di atas"
      ],
      "metadata": {
        "id": "q7hGh5Q6bOwN"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rx, ry, rz = rxs[idx], rys[idx], rzs[idx]\n",
        "x, y, z = xs[idx], ys[idx], zs[idx]\n",
        "rx, ry, rz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nNAbKs0bY9Y",
        "outputId": "3d1b7554-ba87-4ff4-d5be-04e9d7ce2732"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([4, 3, 8, 3, 2]), tensor([9, 6, 2, 6, 2]), tensor([9, 6, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_topk(outp, k=5):\n",
        "    probs = F.softmax(outp,dim=-1)\n",
        "    vals,idxs = probs.topk(k, dim=-1)\n",
        "    return idxs[torch.randint(k, (1,))]"
      ],
      "metadata": {
        "id": "HNDkuTW5bvyx"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "\n",
        "def select_nucleus(outp, p=0.5):\n",
        "    probs = F.softmax(outp,dim=-1)\n",
        "    idxs = torch.argsort(probs, descending=True)\n",
        "    res,cumsum = [],0.\n",
        "    for idx in idxs:\n",
        "        res.append(idx)\n",
        "        cumsum += probs[idx]\n",
        "        if cumsum>p: return idxs.new_tensor([choice(res)])"
      ],
      "metadata": {
        "id": "FgYclITQb2-9"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(self, inp):\n",
        "    inp = inp[None]\n",
        "    bs, sl = inp.size()\n",
        "    hid,enc_out = self.encoder(bs, inp)\n",
        "    dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
        "    enc_att = self.enc_att(enc_out)\n",
        "\n",
        "    res = []\n",
        "    for i in range(self.out_sl):\n",
        "        hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
        "        dec_inp = select_nucleus(outp[0], p=0.3)\n",
        "#         dec_inp = select_topk(outp[0], k=2)\n",
        "        res.append(dec_inp)\n",
        "        if (dec_inp==self.pad_idx).all(): break\n",
        "    return torch.cat(res)"
      ],
      "metadata": {
        "id": "v2Qj8A-8b7DC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uQ8MWg6cqPV",
        "outputId": "fc3580cc-1aa4-48fd-94a6-a3aeb337ff28"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 3, 8, 3, 2]\n",
            "[9, 6, 2, 6, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_decode(learn, x, y):\n",
        "    learn.model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = decode(learn.model, x)\n",
        "    return x, y, out.argmax(-1)"
      ],
      "metadata": {
        "id": "pxwsotqIb9kh"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = rxs[0]\n",
        "y = rys[0]"
      ],
      "metadata": {
        "id": "EQcTuGlCcCQC"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rx,ry,rz = predict_with_decode(learn, x, y)\n",
        "rz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pK6MaXydAdr",
        "outputId": "4062d06b-c806-48b1-bc80-cf9d16a5f791"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}